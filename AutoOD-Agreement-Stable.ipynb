{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.io import arff\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn import metrics\n",
    "import scipy as sp\n",
    "import logging\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from warnings import simplefilter\n",
    "simplefilter(action='ignore', category=FutureWarning)\n",
    "    \n",
    "def run_lof(X, y, k=60):\n",
    "    clf = LocalOutlierFactor(n_neighbors=k)\n",
    "    clf.fit(X)\n",
    "    lof_scores = -clf.negative_outlier_factor_\n",
    "    return lof_scores\n",
    "\n",
    "def get_predictions(scores, num_outliers = 400, method_name = 'LOF'):\n",
    "    threshold = np.sort(scores)[::-1][num_outliers]\n",
    "    # threshold, max_f1 = get_best_f1_score(y, lof_scores)\n",
    "    predictions = np.array(scores > threshold)\n",
    "    predictions = np.array([int(i) for i in predictions])\n",
    "#     print('F1 for {} : {}'.format(method_name, metrics.f1_score(y, predictions)))\n",
    "    return predictions, scores, metrics.f1_score(y, predictions)\n",
    "\n",
    "def get_best_F1(scores):\n",
    "    best_f1 = 0\n",
    "    for i in range(np.shape(scores)[0]):\n",
    "        threshold = np.sort(scores)[::-1][i]\n",
    "        predictions = np.array(scores > threshold)\n",
    "        predictions = np.array([int(i) for i in predictions])\n",
    "        cur_f1 = metrics.f1_score(y, predictions)\n",
    "        best_f1 = max(cur_f1, best_f1)\n",
    "    return best_f1\n",
    "\n",
    "def run_knn(X, y, k=60):\n",
    "    neigh = NearestNeighbors(n_neighbors=k)\n",
    "    neigh.fit(X)\n",
    "    knn_dists = neigh.kneighbors(X)[0][:,-1]\n",
    "    return knn_dists\n",
    "\n",
    "def run_isolation_forest(X, y, max_features = 1.0):\n",
    "    # training the model\n",
    "    clf = IsolationForest(random_state=42,max_features=max_features)\n",
    "    clf.fit(X)\n",
    "    # predictions\n",
    "    sklearn_score_anomalies = clf.decision_function(X)\n",
    "    if_scores = [-1*s + 0.5 for s in sklearn_score_anomalies]\n",
    "    return if_scores\n",
    "\n",
    "def mahalanobis(x):\n",
    "    \"\"\"Compute the Mahalanobis Distance between each row of x and the data\n",
    "    \"\"\"\n",
    "    x_minus_mu = x - np.mean(x)\n",
    "    cov = np.cov(x.T)\n",
    "    inv_covmat = sp.linalg.inv(cov)\n",
    "    results = []\n",
    "    x_minus_mu = np.array(x_minus_mu)\n",
    "    for i in range(np.shape(x)[0]):\n",
    "        cur_data = x_minus_mu[i,:]\n",
    "        results.append(np.dot(np.dot(x_minus_mu[i,:], inv_covmat), x_minus_mu[i,:].T))\n",
    "    return np.array(results)\n",
    "#     left_term = np.dot(x_minus_mu, inv_covmat)\n",
    "#     mahal = np.dot(left_term, x_minus_mu.T)\n",
    "#     print(mahal.diagonal())\n",
    "#     return mahal.diagonal()\n",
    "\n",
    "def run_mahalanobis(X, y):\n",
    "    # training the model\n",
    "    dist = mahalanobis(x=X)\n",
    "    return dist\n",
    "\n",
    "def load_dataset(filename):\n",
    "    with open(filename, 'r') as f:\n",
    "        data, meta = arff.loadarff(f)\n",
    "    data = pd.DataFrame(data)\n",
    "    X = data.drop(columns=['id', 'outlier'])\n",
    "    # Map dataframe to encode values and put values into a numpy array\n",
    "    y = data[\"outlier\"].map(lambda x: 1 if x == b'yes' else 0).values\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load SpamBase dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = './SpamBase_withoutdupl_norm_40.arff'\n",
    "X, y = load_dataset(filename=filename)\n",
    "print(np.shape(X), np.shape(y))\n",
    "K = 9\n",
    "N = 1679\n",
    "class_balance = [1- N/4207.0, N/4207.0]\n",
    "lof_krange = list(range(10,110,10)) * 6\n",
    "knn_krange = list(range(10,110,10)) * 6\n",
    "if_range = [0.5, 0.6, 0.7, 0.8, 0.9] * 6\n",
    "# mahalanobis_N_range=[N]\n",
    "mahalanobis_N_range = [1400, 1500, 1600, 1700, 1800, 1900]\n",
    "if_N_range = np.sort(mahalanobis_N_range * 5)\n",
    "N_range = np.sort(mahalanobis_N_range * 10) \n",
    "print(N/len(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load pageblock dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5473, 10) (5473,)\n"
     ]
    }
   ],
   "source": [
    "filename = './PageBlocks/PageBlocks_norm_10.arff'\n",
    "X, y = load_dataset(filename=filename)\n",
    "print(np.shape(X), np.shape(y))\n",
    "K = 80\n",
    "N = 560\n",
    "# num_outliers = [N, N, N, N]\n",
    "class_balance = [0.9, 0.1]\n",
    "# lof_krange = [55, 60, 65, 70, 75] \n",
    "# knn_krange = [55, 60, 65, 70, 75] \n",
    "# if_range = [0.5, 0.6,0.7, 0.8,0.9]\n",
    "lof_krange = list(range(10,110,10)) * 6\n",
    "knn_krange = list(range(10,110,10)) * 6\n",
    "# lof_krange = range(70,90,4) \n",
    "# knn_krange = [60, 70, 80, 90, 100] \n",
    "if_range = [0.5, 0.6, 0.7, 0.8, 0.9] * 6\n",
    "# mahalanobis_N_range=[560]\n",
    "mahalanobis_N_range = [300, 400, 500, 600, 700, 800]\n",
    "# mahalanobis_N_range = [550, 560, 570, 580, 590, 600]\n",
    "N_size = 6\n",
    "if_N_range = np.sort(mahalanobis_N_range * 5)\n",
    "N_range = np.sort(mahalanobis_N_range * 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Hepatitis dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = './Hepatitis_withoutdupl_norm_16.arff'\n",
    "X, y = load_dataset(filename=filename)\n",
    "print(np.shape(X), np.shape(y))\n",
    "N = 19\n",
    "print(sum(y))\n",
    "class_balance = [1- N/80.0, N/80.0]\n",
    "lof_krange = list(range(2,22,2)) * 6\n",
    "knn_krange = list(range(2,22,2)) * 6\n",
    "if_range = [0.5, 0.6, 0.7, 0.8, 0.9] * 6 \n",
    "mahalanobis_N_range=[N]\n",
    "mahalanobis_N_range = [10, 12, 15, 18, 20, 25]\n",
    "if_N_range = np.sort(mahalanobis_N_range * 5)\n",
    "N_range = np.sort(mahalanobis_N_range * 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Pima dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = './Pima_withoutdupl_norm_35.arff'\n",
    "X, y = load_dataset(filename=filename)\n",
    "print(np.shape(X), np.shape(y))\n",
    "K = 100\n",
    "N = 268\n",
    "print(N/len(y))\n",
    "num_outliers = [N, N, N, N]\n",
    "class_balance = [1- N/768.0, N/768.0]\n",
    "lof_krange = list(range(10,210,10)) * 6\n",
    "knn_krange = list(range(10,210,10)) * 6\n",
    "if_range = [0.5, 0.6, 0.7, 0.8, 0.9] * 6\n",
    "mahalanobis_N_range=[N]\n",
    "mahalanobis_N_range = [220,230,240,250,260,270]\n",
    "\n",
    "if_N_range = np.sort(mahalanobis_N_range * 5)\n",
    "N_range = np.sort(mahalanobis_N_range * 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ALOI dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = './ALOI_withoutdupl_norm.arff'\n",
    "X, y = load_dataset(filename=filename)\n",
    "print(np.shape(X), np.shape(y))\n",
    "print(sum(y))\n",
    "N = 1508\n",
    "num_outliers = [N, N, N, N]\n",
    "class_balance = [1- N/49534.0, N/49534.0]\n",
    "lof_krange = list(range(10,110,10)) * 6\n",
    "knn_krange = list(range(10,110,10)) * 6\n",
    "if_range = [0.5, 0.6, 0.7, 0.8, 0.9] * 6\n",
    "# mahalanobis_N_range=[N]\n",
    "mahalanobis_N_range=[1500, 2000, 2500, 3000, 3500, 4000]\n",
    "if_N_range = np.sort(mahalanobis_N_range * 5)\n",
    "N_range = np.sort(mahalanobis_N_range *10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load InternetAds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = './InternetAds_withoutdupl_norm_19.arff'\n",
    "X, y = load_dataset(filename=filename)\n",
    "print(np.shape(X), np.shape(y))\n",
    "print(sum(y))\n",
    "N = 368\n",
    "num_outliers = [N, N, N, N]\n",
    "class_balance = [1- N/1966.0, N/1966.0]\n",
    "lof_krange = list(range(5,55,5)) * 6\n",
    "knn_krange = list(range(5,55,5)) * 6\n",
    "if_range = [0.5, 0.6, 0.7, 0.8, 0.9] * 6\n",
    "# mahalanobis_N_range=[N]\n",
    "mahalanobis_N_range = [300, 350, 400, 450, 500, 550]\n",
    "if_N_range = np.sort(mahalanobis_N_range * 5)\n",
    "N_range = np.sort(mahalanobis_N_range *10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load KDDCup 99 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = './KDDCup99_withoutdupl_norm_catremoved.arff'\n",
    "X, y = load_dataset(filename=filename)\n",
    "print(np.shape(X), np.shape(y))\n",
    "print(sum(y))\n",
    "N = 200\n",
    "num_outliers = [N, N, N, N]\n",
    "class_balance = [1- N/48113.0, N/48113.0]\n",
    "lof_krange = list(range(10,110,10)) * 6\n",
    "knn_krange = list(range(10,110,10)) * 6\n",
    "if_range = [0.5, 0.6, 0.7, 0.8, 0.9] * 6\n",
    "mahalanobis_N_range=[500,1000,1500,2000,2500,3000]\n",
    "# mahalanobis_N_range = [20, 40, 60,80, 100,120]\n",
    "if_N_range = np.sort(mahalanobis_N_range * 5)\n",
    "N_range = np.sort(mahalanobis_N_range *10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename='kdd99-unsupervised-ad.csv'\n",
    "import pandas as pd\n",
    "data = pd.read_csv(filename, header=None)\n",
    "X = data.drop(columns=[29])\n",
    "print(np.shape(np.array(X)))\n",
    "# Map dataframe to encode values and put values into a numpy array\n",
    "y = data[29].map(lambda x: 1 if x == 'o' else 0).values\n",
    "print(sum(y))\n",
    "\n",
    "lof_krange = list(range(10,110,10)) * 6\n",
    "knn_krange = list(range(10,110,10)) * 6\n",
    "if_range = [0.5, 0.6, 0.7, 0.8, 0.9] * 6\n",
    "mahalanobis_N_range=[1000,1500,2000,2500,3000,3500]\n",
    "if_N_range = np.sort(mahalanobis_N_range * 5)\n",
    "N_range = np.sort(mahalanobis_N_range *10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load shuttle dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hdf5storage\n",
    "mat = hdf5storage.loadmat('shuttle.mat')\n",
    "X = mat['X']\n",
    "y = mat['y']\n",
    "print(len(y))\n",
    "print(np.sum(y)/len(y))\n",
    "lof_krange = list(range(10,110,10)) * 6\n",
    "knn_krange = list(range(10,110,10)) * 6\n",
    "if_range = [0.5, 0.6, 0.7, 0.8, 0.9] * 6\n",
    "mahalanobis_N_range=[1000,1500,2000, 2500,3000, 3500]\n",
    "# mahalanobis_N_range = [20, 40, 60,80, 100,120]\n",
    "if_N_range = np.sort(mahalanobis_N_range * 5)\n",
    "N_range = np.sort(mahalanobis_N_range *10)\n",
    "print(np.shape(X))\n",
    "\n",
    "# normalize\n",
    "# from sklearn.preprocessing import Normalizer\n",
    "# transformer = Normalizer().fit(X) \n",
    "# X = transformer.transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load mulcross dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = './mulcross.arff'\n",
    "\n",
    "with open(filename, 'r') as f:\n",
    "    data, meta = arff.loadarff(f)\n",
    "data = pd.DataFrame(data)\n",
    "X = data.drop(columns=['Target'])\n",
    "y = data[\"Target\"].map(lambda x: 1 if x == b'Anomaly' else 0).values\n",
    "# X, y = load_dataset(filename=filename)\n",
    "print(np.shape(X), np.shape(y))\n",
    "print(sum(y))\n",
    "print(sum(y)/len(y))\n",
    "lof_krange = list(range(10,110,10)) * 6\n",
    "knn_krange = list(range(10,110,10)) * 6\n",
    "if_range = [0.5, 0.6, 0.7, 0.8, 0.9] * 6\n",
    "mahalanobis_N_range=[20000, 22000, 24000, 26000, 28000, 30000]\n",
    "# mahalanobis_N_range = [20, 40, 60,80, 100,120]\n",
    "if_N_range = np.sort(mahalanobis_N_range * 5)\n",
    "N_range = np.sort(mahalanobis_N_range *10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load HTTP dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hdf5storage\n",
    "mat = hdf5storage.loadmat('http.mat')\n",
    "X = mat['X']\n",
    "y = mat['y']\n",
    "print(len(y))\n",
    "print(np.sum(y))\n",
    "print(np.sum(y)/len(y))\n",
    "lof_krange = list(range(10,110,10)) * 6\n",
    "knn_krange = list(range(10,110,10)) * 6\n",
    "if_range = [0.5, 0.6, 0.7, 0.8, 0.9] * 6\n",
    "# mahalanobis_N_range=[1500, 2000, 2500, 3000, 3500, 4000]\n",
    "mahalanobis_N_range=[5000, 10000, 15000,20000, 25000, 30000]\n",
    "# mahalanobis_N_range=[10000, 15000, 20000, 25000, 30000, 35000]\n",
    "# mahalanobis_N_range = [20, 40, 60,80, 100,120]\n",
    "if_N_range = np.sort(mahalanobis_N_range * 5)\n",
    "N_range = np.sort(mahalanobis_N_range *10)\n",
    "\n",
    "# # remove duplicates\n",
    "# newdata = pd.DataFrame(np.concatenate((X,y), axis = 1)).drop_duplicates()\n",
    "# X = newdata[[0,1,2]].values\n",
    "# y = np.array([1 if i==1.0 else 0 for i in newdata[[3]].values])\n",
    "# print('Remove duplicates: ', len(y))\n",
    "\n",
    "# # normalize\n",
    "# from sklearn.preprocessing import Normalizer\n",
    "# transformer = Normalizer().fit(X) \n",
    "# X = transformer.transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load ForestCover Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hdf5storage\n",
    "import pickle\n",
    "dataset = pickle.load(open(\"cover_dataset.pickle\", \"rb\"))\n",
    "X = dataset['X']\n",
    "y = dataset['y']\n",
    "print(np.sum(y))\n",
    "print(len(y))\n",
    "lof_krange = list(range(10,110,10)) * 6\n",
    "knn_krange = list(range(10,110,10)) * 6\n",
    "if_range = [0.5, 0.6, 0.7, 0.8, 0.9] * 6\n",
    "mahalanobis_N_range=[5000, 8000, 10000, 12000, 15000, 18000]\n",
    "# mahalanobis_N_range = [20, 40, 60,80, 100,120]\n",
    "if_N_range = np.sort(mahalanobis_N_range * 5)\n",
    "N_range = np.sort(mahalanobis_N_range *10)\n",
    "\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "transformer = RobustScaler().fit(X)\n",
    "X_transformed = transformer.transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Annthyroid dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = './Annthyroid_withoutdupl_norm_07.arff'\n",
    "X, y = load_dataset(filename=filename)\n",
    "print(np.shape(X), np.shape(y))\n",
    "print(sum(y)/len(y))\n",
    "N = 534\n",
    "num_outliers = [N, N, N, N]\n",
    "class_balance = [1- N/7129.0, N/7129.0]\n",
    "lof_krange = list(range(10,110,10)) * 6\n",
    "knn_krange = list(range(10,110,10)) * 6\n",
    "if_range = [0.5, 0.6, 0.7, 0.8, 0.9] * 6\n",
    "# mahalanobis_N_range=[N]\n",
    "mahalanobis_N_range=[300, 400,500,600,700,800]\n",
    "if_N_range = np.sort(mahalanobis_N_range * 5)\n",
    "N_range = np.sort(mahalanobis_N_range *10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hdf5storage\n",
    "mat = hdf5storage.loadmat('smtp.mat')\n",
    "X = mat['X']\n",
    "y = mat['y']\n",
    "print(len(y))\n",
    "print(np.sum(y))\n",
    "\n",
    "lof_krange = list(range(10,110,10)) * 6\n",
    "knn_krange = list(range(10,110,10)) * 6\n",
    "if_range = [0.5, 0.6, 0.7, 0.8, 0.9] * 6\n",
    "# mahalanobis_N_range=[20, 40, 60, 80, 100, 120]\n",
    "mahalanobis_N_range = [50, 100, 150, 200, 250, 300]\n",
    "# mahalanobis_N_range = [200, 400, 600, 800, 1000, 1200]\n",
    "if_N_range = np.sort(mahalanobis_N_range * 5)\n",
    "N_range = np.sort(mahalanobis_N_range *10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hdf5storage\n",
    "mat = hdf5storage.loadmat('cardio.mat')\n",
    "X = mat['X']\n",
    "y = mat['y']\n",
    "print(len(y))\n",
    "print(np.sum(y)/len(y))\n",
    "lof_krange = list(range(10,110,10)) * 6\n",
    "knn_krange = list(range(10,110,10)) * 6\n",
    "if_range = [0.5, 0.6, 0.7, 0.8, 0.9] * 6\n",
    "mahalanobis_N_range=[150,200,250,300,350,400]\n",
    "# mahalanobis_N_range = [20, 40, 60,80, 100,120]\n",
    "if_N_range = np.sort(mahalanobis_N_range * 5)\n",
    "N_range = np.sort(mahalanobis_N_range *10)\n",
    "print(np.shape(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOF k = 10, best F-1 = 0.39999999999999997\n",
      "LOF k = 20, best F-1 = 0.4520833333333334\n",
      "LOF k = 30, best F-1 = 0.42499999999999993\n",
      "LOF k = 40, best F-1 = 0.4547169811320755\n",
      "LOF k = 50, best F-1 = 0.49056603773584906\n",
      "LOF k = 60, best F-1 = 0.5020833333333333\n",
      "LOF k = 70, best F-1 = 0.5018867924528301\n",
      "LOF k = 80, best F-1 = 0.5120689655172415\n",
      "LOF k = 90, best F-1 = 0.4862068965517241\n",
      "LOF k = 100, best F-1 = 0.4773584905660378\n",
      "Best LOF F-1 = 0.5120689655172415\n",
      "100\n",
      "70\n",
      "40\n",
      "10\n",
      "80\n",
      "50\n",
      "20\n",
      "90\n",
      "60\n",
      "30\n",
      "KNN k = 10, best F-1 = 0.39841269841269844\n",
      "KNN k = 20, best F-1 = 0.42698412698412697\n",
      "KNN k = 30, best F-1 = 0.42698412698412697\n",
      "KNN k = 40, best F-1 = 0.43333333333333335\n",
      "KNN k = 50, best F-1 = 0.4317460317460317\n",
      "KNN k = 60, best F-1 = 0.42758620689655175\n",
      "KNN k = 70, best F-1 = 0.4241379310344828\n",
      "KNN k = 80, best F-1 = 0.4190476190476191\n",
      "KNN k = 90, best F-1 = 0.4174603174603174\n",
      "KNN k = 100, best F-1 = 0.41764705882352937\n",
      "Best KNN F-1 = 0.43333333333333335\n",
      "0.5\n",
      "0.6\n",
      "0.8\n",
      "0.9\n",
      "0.7\n",
      "IF = 0.5, best F-1 = 0.4094339622641509\n",
      "IF = 0.6, best F-1 = 0.43396226415094336\n",
      "IF = 0.7, best F-1 = 0.4037735849056604\n",
      "IF = 0.8, best F-1 = 0.38113207547169814\n",
      "IF = 0.9, best F-1 = 0.4113207547169811\n",
      "Best IF F-1 = 0.43396226415094336\n",
      "mahalanobis = 0.5411764705882354\n",
      "Best Mahala F-1 = 0.5411764705882354\n"
     ]
    }
   ],
   "source": [
    "all_results = []\n",
    "all_scores = []\n",
    "f1s = []\n",
    "\n",
    "temp_lof_results = dict()\n",
    "unique_lof_ks = list(set(lof_krange)) \n",
    "for k in unique_lof_ks:\n",
    "#     print(k)\n",
    "    lof_scores = run_lof(X, y, k=k)\n",
    "    temp_lof_results[k] = lof_scores\n",
    "for i in range(len(lof_krange)):\n",
    "    lof_predictions, lof_scores, f1 = get_predictions(temp_lof_results[lof_krange[i]], num_outliers=N_range[i], method_name='LOF')\n",
    "    all_results.append(lof_predictions)\n",
    "    all_scores.append(lof_scores)\n",
    "    f1s.append(f1)\n",
    "best_lof_f1 = 0\n",
    "for i in np.sort(unique_lof_ks):\n",
    "    temp_f1 = max(np.array(f1s[0:60])[np.where(np.array(lof_krange) == i)[0]])\n",
    "    print('LOF k = {}, best F-1 = {}'.format(i, temp_f1))\n",
    "    best_lof_f1 = max(best_lof_f1, temp_f1)\n",
    "print('Best LOF F-1 = {}'.format(best_lof_f1))\n",
    "\n",
    "temp_knn_results = dict()\n",
    "unique_knn_ks = list(set(knn_krange)) \n",
    "for k in unique_knn_ks:\n",
    "    print(k)\n",
    "    knn_scores = run_knn(X, y, k=k)\n",
    "    temp_knn_results[k] = knn_scores\n",
    "for i in range(len(knn_krange)):\n",
    "    knn_predictions, knn_scores,f1 = get_predictions(temp_knn_results[knn_krange[i]], num_outliers=N_range[i], method_name='KNN')\n",
    "    all_results.append(knn_predictions)\n",
    "    all_scores.append(knn_scores)\n",
    "    f1s.append(f1)\n",
    "best_knn_f1 = 0\n",
    "for i in np.sort(unique_knn_ks):\n",
    "    temp_f1 = max(np.array(f1s[60:120])[np.where(np.array(knn_krange) == i)[0]])\n",
    "    print('KNN k = {}, best F-1 = {}'.format(i, temp_f1))\n",
    "    best_knn_f1 = max(best_knn_f1, temp_f1)\n",
    "print('Best KNN F-1 = {}'.format(best_knn_f1))\n",
    "    \n",
    "temp_if_results = dict()\n",
    "unique_if_features = list(set(if_range)) \n",
    "for k in unique_if_features:\n",
    "    print(k)\n",
    "    if_scores = run_isolation_forest(X, y, max_features=k)\n",
    "    temp_if_results[k] = if_scores\n",
    "for i in range(len(if_range)):\n",
    "    if_predictions, if_scores,f1 = get_predictions(temp_if_results[if_range[i]], num_outliers=N_range[i], method_name='IF')\n",
    "    all_results.append(if_predictions)\n",
    "    all_scores.append(if_scores)\n",
    "    f1s.append(f1)\n",
    "best_if_f1 = 0\n",
    "for i in np.sort(unique_if_features):\n",
    "    temp_f1 = max(np.array(f1s[120:150])[np.where(np.array(if_range) == i)[0]])\n",
    "    print('IF = {}, best F-1 = {}'.format(i, temp_f1))\n",
    "    best_if_f1 = max(best_if_f1, temp_f1)\n",
    "print('Best IF F-1 = {}'.format(best_if_f1))\n",
    "    \n",
    "mahalanobis_scores = run_mahalanobis(X, y)\n",
    "best_mahala_f1 = 0\n",
    "for i in range(len(mahalanobis_N_range)):\n",
    "    mahalanobis_predictions,mahalanobis_scores,f1 = get_predictions(mahalanobis_scores, num_outliers=mahalanobis_N_range[i], method_name='mahala')\n",
    "    all_results.append(mahalanobis_predictions)\n",
    "    all_scores.append(mahalanobis_scores)\n",
    "    best_mahala_f1 = max(best_mahala_f1, f1)\n",
    "    f1s.append(f1)\n",
    "print('mahalanobis = {}'.format(max(np.array(f1s[150:]))))\n",
    "print('Best Mahala F-1 = {}'.format(best_mahala_f1))\n",
    "L = np.stack(all_results).T\n",
    "scores = np.stack(all_scores).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5473, 156)\n",
      "(5473, 156)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(L))\n",
    "print(np.shape(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Majority Vote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 for MV: 0.43640124095139604\n"
     ]
    }
   ],
   "source": [
    "mid = np.shape(L)[1]/2\n",
    "predictions = np.full((len(y)), 0)\n",
    "predictions[np.sum(L, axis = 1) > mid] = 1\n",
    "print('F1 for MV:', metrics.f1_score(y, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save and load pickles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "L_prev = L\n",
    "scores_prev = scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = L_prev\n",
    "scores = scores_prev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5473, 156)\n"
     ]
    }
   ],
   "source": [
    "# print(max(f1s)) \n",
    "print(np.shape(L))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_result_list = []\n",
    "classifier_result_list = []\n",
    "prediction_list = []\n",
    "cur_f1_scores = []\n",
    "prediction_high_conf_outliers = np.array([])\n",
    "prediction_high_conf_inliers = np.array([])\n",
    "prediction_classifier_disagree = np.array([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_range = np.array([[0, 60], [60, 120], [120, 150], [150, 156]])\n",
    "coef_index_range = np.array([[0, 10], [10, 20], [20, 25], [25, 26]])\n",
    "coef_remain_index = range(156)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index_range = np.array([[0, 120], [120, 240], [240, 270], [270, 276]])\n",
    "# coef_index_range = np.array([[0, 20], [20, 40], [40, 45], [45, 46]])\n",
    "# coef_remain_index = range(276)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 120, 121, 122, 123, 124, 150]\n",
      "(5473, 26)\n"
     ]
    }
   ],
   "source": [
    "scores_for_training_indexes = []\n",
    "for i in range(len(index_range)):\n",
    "    start=index_range[i][0]\n",
    "    temp_range = coef_index_range[i][1]-coef_index_range[i][0]\n",
    "    scores_for_training_indexes  = scores_for_training_indexes + list(range(start, start+temp_range))\n",
    "print(scores_for_training_indexes) \n",
    "scores_for_training = scores[:, np.array(scores_for_training_indexes)]\n",
    "print(np.shape(scores_for_training))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterative train LR and classifier(SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##################################################################\n",
      "Iteration = 0, L shape = (5473, 156)\n",
      "num of outliers = 55\n",
      "Training data shape:  (3843, 26)\n",
      "Training data F-1 0.48\n",
      "(3843, 10)\n",
      "(3843,)\n",
      "F-1 score from SVM: 0.492436974789916\n",
      "Number of outliers by SVM: 645.0\n",
      "F-1 score from LR: 0.38451612903225807\n",
      "Number of outliers by LR:  215\n",
      "[[1.        0.6164632]\n",
      " [0.6164632 1.       ]]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 23 25]\n",
      "[[ 0 10]\n",
      " [10 20]\n",
      " [20 21]\n",
      " [21 22]]\n",
      "##################################################################\n",
      "Iteration = 1, L shape = (5473, 132)\n",
      "num of outliers = 57\n",
      "Training data shape:  (3844, 22)\n",
      "Training data F-1 0.48684210526315785\n",
      "(3844, 10)\n",
      "(3844,)\n",
      "F-1 score from SVM: 0.49372384937238495\n",
      "Number of outliers by SVM: 652.0\n",
      "F-1 score from LR: 0.3891752577319587\n",
      "Number of outliers by LR:  216\n",
      "[[1.         0.60554473]\n",
      " [0.60554473 1.        ]]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 25]\n",
      "[[ 0 10]\n",
      " [10 20]\n",
      " [20 20]\n",
      " [20 21]]\n",
      "##################################################################\n",
      "Iteration = 2, L shape = (5473, 126)\n",
      "num of outliers = 63\n",
      "Training data shape:  (3850, 21)\n",
      "Training data F-1 0.48750000000000004\n",
      "(3850, 10)\n",
      "(3850,)\n",
      "F-1 score from SVM: 0.4975124378109453\n",
      "Number of outliers by SVM: 653.0\n",
      "F-1 score from LR: 0.38974358974358975\n",
      "Number of outliers by LR:  220\n",
      "[[1.         0.59698576]\n",
      " [0.59698576 1.        ]]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 25]\n",
      "[[ 0 10]\n",
      " [10 19]\n",
      " [19 19]\n",
      " [19 20]]\n",
      "##################################################################\n",
      "Iteration = 3, L shape = (5473, 120)\n",
      "num of outliers = 66\n",
      "Training data shape:  (3856, 20)\n",
      "Training data F-1 0.4880952380952381\n",
      "(3856, 10)\n",
      "(3856,)\n",
      "F-1 score from SVM: 0.49372384937238495\n",
      "Number of outliers by SVM: 653.0\n",
      "F-1 score from LR: 0.39180537772087065\n",
      "Number of outliers by LR:  221\n",
      "[[1.         0.60419394]\n",
      " [0.60419394 1.        ]]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 25]\n",
      "[[ 0 10]\n",
      " [10 18]\n",
      " [18 18]\n",
      " [18 19]]\n",
      "##################################################################\n",
      "Iteration = 4, L shape = (5473, 114)\n",
      "num of outliers = 68\n",
      "Training data shape:  (3862, 19)\n",
      "Training data F-1 0.4855491329479769\n",
      "(3862, 10)\n",
      "(3862,)\n",
      "F-1 score from SVM: 0.492436974789916\n",
      "Number of outliers by SVM: 654.0\n",
      "F-1 score from LR: 0.3908629441624366\n",
      "Number of outliers by LR:  228\n",
      "[[1.         0.61026802]\n",
      " [0.61026802 1.        ]]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 25]\n",
      "[[ 0 10]\n",
      " [10 16]\n",
      " [16 16]\n",
      " [16 17]]\n",
      "##################################################################\n",
      "Iteration = 5, L shape = (5473, 102)\n",
      "num of outliers = 74\n",
      "Training data shape:  (3872, 17)\n",
      "Training data F-1 0.49729729729729716\n",
      "(3872, 10)\n",
      "(3872,)\n",
      "F-1 score from SVM: 0.4975124378109453\n",
      "Number of outliers by SVM: 662.0\n",
      "F-1 score from LR: 0.40597758405977585\n",
      "Number of outliers by LR:  243\n",
      "[[1.         0.60292279]\n",
      " [0.60292279 1.        ]]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 25]\n",
      "[[ 0 10]\n",
      " [10 12]\n",
      " [12 12]\n",
      " [12 13]]\n",
      "##################################################################\n",
      "Iteration = 6, L shape = (5473, 78)\n",
      "num of outliers = 84\n",
      "Training data shape:  (3886, 13)\n",
      "Training data F-1 0.49494949494949503\n",
      "(3886, 10)\n",
      "(3886,)\n",
      "F-1 score from SVM: 0.4903765690376569\n",
      "Number of outliers by SVM: 668.0\n",
      "F-1 score from LR: 0.42002442002442003\n",
      "Number of outliers by LR:  259\n",
      "[[1.         0.61655964]\n",
      " [0.61655964 1.        ]]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 25]\n",
      "[[ 0 10]\n",
      " [10 11]\n",
      " [11 11]\n",
      " [11 12]]\n",
      "##################################################################\n",
      "Iteration = 7, L shape = (5473, 72)\n",
      "num of outliers = 89\n",
      "Training data shape:  (3898, 12)\n",
      "Training data F-1 0.4975609756097561\n",
      "(3898, 10)\n",
      "(3898,)\n",
      "F-1 score from SVM: 0.493744787322769\n",
      "Number of outliers by SVM: 669.0\n",
      "F-1 score from LR: 0.42460796139927626\n",
      "Number of outliers by LR:  269\n",
      "[[1.         0.61357714]\n",
      " [0.61357714 1.        ]]\n",
      "[ 1  2  3  4  5  6  7  8  9 10 25]\n",
      "[[ 0  9]\n",
      " [ 9 10]\n",
      " [10 10]\n",
      " [10 11]]\n",
      "##################################################################\n",
      "Iteration = 8, L shape = (5473, 66)\n",
      "num of outliers = 104\n",
      "Training data shape:  (4059, 11)\n",
      "Training data F-1 0.5333333333333333\n",
      "(4059, 10)\n",
      "(4059,)\n",
      "F-1 score from SVM: 0.5008403361344538\n",
      "Number of outliers by SVM: 652.0\n",
      "F-1 score from LR: 0.43861740166865315\n",
      "Number of outliers by LR:  279\n",
      "[[1.         0.63120111]\n",
      " [0.63120111 1.        ]]\n",
      "[ 1  3  4  5  6  7  8  9 10 25]\n",
      "[[ 0  8]\n",
      " [ 8  9]\n",
      " [ 9  9]\n",
      " [ 9 10]]\n",
      "##################################################################\n",
      "Iteration = 9, L shape = (5473, 60)\n",
      "num of outliers = 106\n",
      "Training data shape:  (4065, 10)\n",
      "Training data F-1 0.5267489711934156\n",
      "(4065, 10)\n",
      "(4065,)\n",
      "F-1 score from SVM: 0.49447748513169076\n",
      "Number of outliers by SVM: 645.0\n",
      "F-1 score from LR: 0.4359281437125749\n",
      "Number of outliers by LR:  275\n",
      "[[1.         0.63896363]\n",
      " [0.63896363 1.        ]]\n",
      "[ 1  3  4  5  6  7  8  9 25]\n",
      "[[0 8]\n",
      " [8 8]\n",
      " [8 8]\n",
      " [8 9]]\n",
      "##################################################################\n",
      "Iteration = 10, L shape = (5473, 54)\n",
      "num of outliers = 111\n",
      "Training data shape:  (4164, 9)\n",
      "Training data F-1 0.5099601593625498\n",
      "(4164, 10)\n",
      "(4164,)\n",
      "F-1 score from SVM: 0.5068259385665529\n",
      "Number of outliers by SVM: 631.0\n",
      "F-1 score from LR: 0.463963963963964\n",
      "Number of outliers by LR:  328\n",
      "[[1.         0.66770572]\n",
      " [0.66770572 1.        ]]\n",
      "[ 1  3  5  6  7  8  9 25]\n",
      "[[0 7]\n",
      " [7 7]\n",
      " [7 7]\n",
      " [7 8]]\n",
      "##################################################################\n",
      "Iteration = 11, L shape = (5473, 48)\n",
      "num of outliers = 123\n",
      "Training data shape:  (4186, 8)\n",
      "Training data F-1 0.4981132075471698\n",
      "(4186, 10)\n",
      "(4186,)\n",
      "F-1 score from SVM: 0.5065502183406114\n",
      "Number of outliers by SVM: 620.0\n",
      "F-1 score from LR: 0.47176079734219273\n",
      "Number of outliers by LR:  343\n",
      "[[1.        0.6944053]\n",
      " [0.6944053 1.       ]]\n",
      "[ 3  5  6  7  8  9 25]\n",
      "[[0 6]\n",
      " [6 6]\n",
      " [6 6]\n",
      " [6 7]]\n",
      "##################################################################\n",
      "Iteration = 12, L shape = (5473, 42)\n",
      "num of outliers = 135\n",
      "Training data shape:  (4317, 7)\n",
      "Training data F-1 0.4919093851132686\n",
      "(4317, 10)\n",
      "(4317,)\n",
      "F-1 score from SVM: 0.5161290322580645\n",
      "Number of outliers by SVM: 614.0\n",
      "F-1 score from LR: 0.46878422782037243\n",
      "Number of outliers by LR:  353\n",
      "[[1.         0.70493863]\n",
      " [0.70493863 1.        ]]\n",
      "[ 3  5  6  7  8 25]\n",
      "[[0 5]\n",
      " [5 5]\n",
      " [5 5]\n",
      " [5 6]]\n",
      "##################################################################\n",
      "Iteration = 13, L shape = (5473, 36)\n",
      "num of outliers = 135\n",
      "Training data shape:  (4335, 6)\n",
      "Training data F-1 0.49358974358974367\n",
      "(4335, 10)\n",
      "(4335,)\n",
      "F-1 score from SVM: 0.5161290322580645\n",
      "Number of outliers by SVM: 603.0\n",
      "F-1 score from LR: 0.46578366445916114\n",
      "Number of outliers by LR:  346\n",
      "[[1.        0.7069658]\n",
      " [0.7069658 1.       ]]\n",
      "[ 5  6  7  8 25]\n",
      "[[0 4]\n",
      " [4 4]\n",
      " [4 4]\n",
      " [4 5]]\n",
      "##################################################################\n",
      "Iteration = 14, L shape = (5473, 30)\n",
      "num of outliers = 174\n",
      "Training data shape:  (4429, 5)\n",
      "Training data F-1 0.5909090909090909\n",
      "(4429, 10)\n",
      "(4429,)\n",
      "F-1 score from SVM: 0.5234782608695652\n",
      "Number of outliers by SVM: 602.0\n",
      "F-1 score from LR: 0.45720720720720714\n",
      "Number of outliers by LR:  328\n",
      "[[1.         0.70624276]\n",
      " [0.70624276 1.        ]]\n",
      "[ 5  6  7 25]\n",
      "[[0 3]\n",
      " [3 3]\n",
      " [3 3]\n",
      " [3 4]]\n",
      "##################################################################\n",
      "Iteration = 15, L shape = (5473, 24)\n",
      "num of outliers = 199\n",
      "Training data shape:  (4470, 4)\n",
      "Training data F-1 0.6261261261261261\n",
      "(4470, 10)\n",
      "(4470,)\n",
      "F-1 score from SVM: 0.5221932114882507\n",
      "Number of outliers by SVM: 601.0\n",
      "F-1 score from LR: 0.4749163879598662\n",
      "Number of outliers by LR:  337\n",
      "[[1.         0.71047185]\n",
      " [0.71047185 1.        ]]\n",
      "[ 5  6 25]\n",
      "[[0 2]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [2 3]]\n",
      "##################################################################\n",
      "Iteration = 16, L shape = (5473, 18)\n",
      "num of outliers = 211\n",
      "Training data shape:  (4498, 3)\n",
      "Training data F-1 0.6425531914893616\n",
      "(4498, 10)\n",
      "(4498,)\n",
      "F-1 score from SVM: 0.522943722943723\n",
      "Number of outliers by SVM: 601.0\n",
      "F-1 score from LR: 0.4716351501668521\n",
      "Number of outliers by LR:  339\n",
      "[[1.         0.71681247]\n",
      " [0.71681247 1.        ]]\n",
      "[5 6]\n",
      "[[0 2]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [2 2]]\n",
      "##################################################################\n",
      "Iteration = 17, L shape = (5473, 12)\n",
      "num of outliers = 261\n",
      "Training data shape:  (4609, 2)\n",
      "Training data F-1 0.6381461675579323\n",
      "(4609, 10)\n",
      "(4609,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-1 score from SVM: 0.56120826709062\n",
      "Number of outliers by SVM: 641.0\n",
      "F-1 score from LR: 0.49907235621521334\n",
      "Number of outliers by LR:  518\n",
      "[[1.         0.69167663]\n",
      " [0.69167663 1.        ]]\n",
      "[5]\n",
      "[[0 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]]\n",
      "##################################################################\n",
      "Iteration = 18, L shape = (5473, 6)\n",
      "num of outliers = 323\n",
      "Training data shape:  (4675, 1)\n",
      "Training data F-1 0.6574923547400613\n",
      "(4675, 10)\n",
      "(4675,)\n",
      "F-1 score from SVM: 0.5723472668810289\n",
      "Number of outliers by SVM: 675.0\n",
      "F-1 score from LR: 0.4909609895337773\n",
      "Number of outliers by LR:  491\n",
      "[[1.         0.71377166]\n",
      " [0.71377166 1.        ]]\n",
      "##################################################################\n",
      "Iteration = 19, L shape = (5473, 6)\n",
      "num of outliers = 289\n",
      "Training data shape:  (4660, 1)\n",
      "Training data F-1 0.6402640264026402\n",
      "(4660, 10)\n",
      "(4660,)\n",
      "F-1 score from SVM: 0.5788617886178863\n",
      "Number of outliers by SVM: 664.0\n",
      "F-1 score from LR: 0.5025432349949136\n",
      "Number of outliers by LR:  423\n",
      "[[1.         0.71053544]\n",
      " [0.71053544 1.        ]]\n",
      "##################################################################\n",
      "Iteration = 20, L shape = (5473, 6)\n",
      "num of outliers = 276\n",
      "Training data shape:  (4660, 1)\n",
      "Training data F-1 0.634974533106961\n",
      "(4660, 10)\n",
      "(4660,)\n",
      "F-1 score from SVM: 0.5789909015715468\n",
      "Number of outliers by SVM: 649.0\n",
      "F-1 score from LR: 0.5015608740894901\n",
      "Number of outliers by LR:  401\n",
      "[[1.         0.71638822]\n",
      " [0.71638822 1.        ]]\n",
      "##################################################################\n",
      "Iteration = 21, L shape = (5473, 6)\n",
      "num of outliers = 276\n",
      "Training data shape:  (4679, 1)\n",
      "Training data F-1 0.6285714285714286\n",
      "(4679, 10)\n",
      "(4679,)\n",
      "F-1 score from SVM: 0.578815679733111\n",
      "Number of outliers by SVM: 645.0\n",
      "F-1 score from LR: 0.5015608740894901\n",
      "Number of outliers by LR:  401\n",
      "[[1.         0.73057189]\n",
      " [0.73057189 1.        ]]\n",
      "##################################################################\n",
      "Iteration = 22, L shape = (5473, 6)\n",
      "num of outliers = 276\n",
      "Training data shape:  (4711, 1)\n",
      "Training data F-1 0.6141215106732348\n",
      "(4711, 10)\n",
      "(4711,)\n",
      "F-1 score from SVM: 0.5884325230511316\n",
      "Number of outliers by SVM: 626.0\n",
      "F-1 score from LR: 0.5015608740894901\n",
      "Number of outliers by LR:  401\n",
      "[[1.         0.73159003]\n",
      " [0.73159003 1.        ]]\n",
      "##################################################################\n",
      "Iteration = 23, L shape = (5473, 6)\n",
      "num of outliers = 276\n",
      "Training data shape:  (4733, 1)\n",
      "Training data F-1 0.611111111111111\n",
      "(4733, 10)\n",
      "(4733,)\n",
      "F-1 score from SVM: 0.5944115156646909\n",
      "Number of outliers by SVM: 613.0\n",
      "F-1 score from LR: 0.5020833333333333\n",
      "Number of outliers by LR:  400\n",
      "[[1.         0.73943304]\n",
      " [0.73943304 1.        ]]\n",
      "##################################################################\n",
      "Iteration = 24, L shape = (5473, 6)\n",
      "num of outliers = 276\n",
      "Training data shape:  (4744, 1)\n",
      "Training data F-1 0.6091205211726385\n",
      "(4744, 10)\n",
      "(4744,)\n",
      "F-1 score from SVM: 0.5932203389830509\n",
      "Number of outliers by SVM: 611.0\n",
      "F-1 score from LR: 0.5020833333333333\n",
      "Number of outliers by LR:  400\n",
      "[[1.         0.73932719]\n",
      " [0.73932719 1.        ]]\n",
      "##################################################################\n",
      "Iteration = 25, L shape = (5473, 6)\n",
      "num of outliers = 276\n",
      "Training data shape:  (4751, 1)\n",
      "Training data F-1 0.6071428571428572\n",
      "(4751, 10)\n",
      "(4751,)\n",
      "F-1 score from SVM: 0.5950554134697357\n",
      "Number of outliers by SVM: 607.0\n",
      "F-1 score from LR: 0.5020833333333333\n",
      "Number of outliers by LR:  400\n",
      "[[1.         0.74337213]\n",
      " [0.74337213 1.        ]]\n",
      "##################################################################\n",
      "Iteration = 26, L shape = (5473, 6)\n",
      "num of outliers = 276\n",
      "Training data shape:  (4763, 1)\n",
      "Training data F-1 0.6032258064516128\n",
      "(4763, 10)\n",
      "(4763,)\n",
      "F-1 score from SVM: 0.5958904109589042\n",
      "Number of outliers by SVM: 602.0\n",
      "F-1 score from LR: 0.5020833333333333\n",
      "Number of outliers by LR:  400\n",
      "[[1.         0.74691847]\n",
      " [0.74691847 1.        ]]\n",
      "##################################################################\n",
      "Iteration = 27, L shape = (5473, 6)\n",
      "num of outliers = 276\n",
      "Training data shape:  (4768, 1)\n",
      "Training data F-1 0.6012861736334406\n",
      "(4768, 10)\n",
      "(4768,)\n",
      "F-1 score from SVM: 0.5972222222222221\n",
      "Number of outliers by SVM: 601.0\n",
      "F-1 score from LR: 0.5020833333333333\n",
      "Number of outliers by LR:  400\n",
      "[[1.         0.75549684]\n",
      " [0.75549684 1.        ]]\n",
      "##################################################################\n",
      "Iteration = 28, L shape = (5473, 6)\n",
      "num of outliers = 276\n",
      "Training data shape:  (4772, 1)\n",
      "Training data F-1 0.6003210272873194\n",
      "(4772, 10)\n",
      "(4772,)\n",
      "F-1 score from SVM: 0.5941780821917808\n",
      "Number of outliers by SVM: 601.0\n",
      "F-1 score from LR: 0.5020833333333333\n",
      "Number of outliers by LR:  400\n",
      "[[1.         0.74656625]\n",
      " [0.74656625 1.        ]]\n",
      "##################################################################\n",
      "Iteration = 29, L shape = (5473, 6)\n",
      "num of outliers = 276\n",
      "Training data shape:  (4772, 1)\n",
      "Training data F-1 0.6003210272873194\n",
      "(4772, 10)\n",
      "(4772,)\n",
      "F-1 score from SVM: 0.5941780821917808\n",
      "Number of outliers by SVM: 601.0\n",
      "F-1 score from LR: 0.5020833333333333\n",
      "Number of outliers by LR:  400\n",
      "[[1.         0.74656625]\n",
      " [0.74656625 1.        ]]\n",
      "##################################################################\n",
      "Iteration = 30, L shape = (5473, 6)\n",
      "num of outliers = 276\n",
      "Training data shape:  (4772, 1)\n",
      "Training data F-1 0.6003210272873194\n",
      "(4772, 10)\n",
      "(4772,)\n",
      "F-1 score from SVM: 0.5941780821917808\n",
      "Number of outliers by SVM: 601.0\n",
      "F-1 score from LR: 0.5020833333333333\n",
      "Number of outliers by LR:  400\n",
      "[[1.         0.74656625]\n",
      " [0.74656625 1.        ]]\n",
      "##################################################################\n",
      "Iteration = 31, L shape = (5473, 6)\n",
      "num of outliers = 276\n",
      "Training data shape:  (4772, 1)\n",
      "Training data F-1 0.6003210272873194\n",
      "(4772, 10)\n",
      "(4772,)\n",
      "F-1 score from SVM: 0.5941780821917808\n",
      "Number of outliers by SVM: 601.0\n",
      "F-1 score from LR: 0.5020833333333333\n",
      "Number of outliers by LR:  400\n",
      "[[1.         0.74656625]\n",
      " [0.74656625 1.        ]]\n",
      "##################################################################\n",
      "Iteration = 32, L shape = (5473, 6)\n",
      "num of outliers = 276\n",
      "Training data shape:  (4772, 1)\n",
      "Training data F-1 0.6003210272873194\n",
      "(4772, 10)\n",
      "(4772,)\n",
      "F-1 score from SVM: 0.5941780821917808\n",
      "Number of outliers by SVM: 601.0\n",
      "F-1 score from LR: 0.5020833333333333\n",
      "Number of outliers by LR:  400\n",
      "[[1.         0.74656625]\n",
      " [0.74656625 1.        ]]\n"
     ]
    }
   ],
   "source": [
    "# stable version\n",
    "high_confidence_threshold = 0.99\n",
    "low_confidence_threshold = 0.01\n",
    "LR_threshold = 0.5\n",
    "max_iter = 200\n",
    "remain_params_tracking = np.array(range(0,np.max(coef_index_range)))\n",
    "training_data_F1 = []\n",
    "two_prediction_corr = []\n",
    "\n",
    "min_max_diff = []\n",
    "N_size = 6\n",
    "\n",
    "last_training_data_indexes = []\n",
    "counter = 0\n",
    "\n",
    "for i_range in range(0, 50):\n",
    "    print(\"##################################################################\")\n",
    "    print('Iteration = {}, L shape = {}'.format(i_range, np.shape(L)))\n",
    "    num_methods = np.shape(L)[1]\n",
    "    \n",
    "    agree_outlier_indexes = np.sum(L,axis=1)==np.shape(L)[1]\n",
    "#     print('All agree, Number of outliers = {}'.format(sum(agree_outlier_indexes)))\n",
    "    agree_inlier_indexes = np.sum(L,axis=1)==0\n",
    "#     print('All agree, Number of inliers = {}'.format(sum(agree_inlier_indexes)))\n",
    "\n",
    "    disagree_indexes = np.where(np.logical_or(np.sum(L,axis = 1)==0, np.sum(L,axis = 1)==num_methods)==0)[0]\n",
    "    \n",
    "#     all_inlier_indexes = np.where(agree_inlier_indexes)[0]\n",
    "    all_inlier_indexes = np.setdiff1d(np.where(agree_inlier_indexes)[0], prediction_high_conf_outliers)\n",
    "    if len(prediction_high_conf_inliers) >0:\n",
    "        all_inlier_indexes = np.intersect1d(np.setdiff1d(np.where(agree_inlier_indexes)[0], prediction_high_conf_outliers), prediction_high_conf_inliers)\n",
    "#     print('num of inliers = {}'.format(np.shape(all_inlier_indexes)[0]))\n",
    "#     all_outlier_indexes = np.union1d(np.where(agree_outlier_indexes)[0], self_agree_index_list)\n",
    "\n",
    "#     if(len(np.intersect1d(np.where(agree_outlier_indexes)[0], prediction_high_conf_outliers)) > 0 and\n",
    "#       (len(np.union1d(np.where(agree_outlier_indexes)[0], prediction_high_conf_outliers)) > 2000)):\n",
    "#         all_outlier_indexes = np.intersect1d(np.where(agree_outlier_indexes)[0], prediction_high_conf_outliers)\n",
    "#     else:\n",
    "    all_outlier_indexes = np.union1d(np.where(agree_outlier_indexes)[0], prediction_high_conf_outliers)\n",
    "#     if(len(all_outlier_indexes) > 1000):\n",
    "#         all_outlier_indexes = np.random.RandomState(1).permutation(all_outlier_indexes)[:1000]\n",
    "        \n",
    "#     all_outlier_indexes = np.union1d(np.where(agree_outlier_indexes)[0], prediction_high_conf_outliers)\n",
    "#     print('num of outliers = {}'.format(np.shape(all_outlier_indexes)[0]))\n",
    "    all_inlier_indexes = np.setdiff1d(all_inlier_indexes, prediction_classifier_disagree)\n",
    "    \n",
    "    self_agree_index_list = []\n",
    "    if((len(all_outlier_indexes) == 0) or (len(all_inlier_indexes)/ len(all_outlier_indexes) > 1000)):\n",
    "        for i in range(0, len(index_range)):\n",
    "            if(index_range[i,1]-index_range[i,0] <= 6):\n",
    "                continue\n",
    "            temp_index = disagree_indexes[np.where(np.sum(L[disagree_indexes][:,index_range[i,0]: index_range[i,1]], axis = 1)==(index_range[i,1]-index_range[i,0]))[0]]\n",
    "            self_agree_index_list = np.union1d(self_agree_index_list, temp_index)\n",
    "        self_agree_index_list = [int(i) for i in self_agree_index_list]\n",
    "#     self_agree_index_list = np.random.RandomState(1).permutation(self_agree_index_list)[:500]\n",
    "    all_outlier_indexes = np.union1d(all_outlier_indexes, self_agree_index_list)\n",
    "    all_outlier_indexes = np.setdiff1d(all_outlier_indexes, prediction_classifier_disagree)\n",
    "    print('num of outliers = {}'.format(np.shape(all_outlier_indexes)[0]))\n",
    "    \n",
    "    \n",
    "    from sklearn.preprocessing import RobustScaler\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    data_indexes = np.concatenate((all_inlier_indexes, all_outlier_indexes), axis = 0)\n",
    "    data_indexes = np.array([int(i) for i in data_indexes])\n",
    "    labels = np.concatenate((np.zeros(len(all_inlier_indexes)), np.ones(len(all_outlier_indexes))), axis = 0)\n",
    "    transformer = RobustScaler().fit(scores_for_training)\n",
    "    scores_transformed = transformer.transform(scores_for_training)\n",
    "    training_data = scores_transformed[data_indexes]\n",
    "    print('Training data shape: ', np.shape(training_data))\n",
    "    training_data_F1.append(metrics.f1_score(y[data_indexes], labels))\n",
    "    print('Training data F-1', metrics.f1_score(y[data_indexes], labels))\n",
    "    \n",
    "    transformer = RobustScaler().fit(X)\n",
    "    X_transformed = transformer.transform(X)\n",
    "    X_training_data = X_transformed[data_indexes]\n",
    "    print(np.shape(X_training_data))\n",
    "    print(np.shape(labels))\n",
    "    \n",
    "    from sklearn.svm import SVC\n",
    "    clf_X = SVC(gamma='auto', probability=True, random_state=0)\n",
    "    clf_X.fit(X_training_data, labels)\n",
    "    clf_predictions_X = clf_X.predict(X_transformed)\n",
    "    clf_predict_proba_X = clf_X.predict_proba(X_transformed)[:,1]\n",
    "    print(\"F-1 score from SVM:\",metrics.f1_score(y, np.array([int(i) for i in clf_predict_proba_X > 0.5])))\n",
    "    cur_f1_scores.append(metrics.f1_score(y, np.array([int(i) for i in clf_predict_proba_X > 0.5])))\n",
    "    print('Number of outliers by SVM:', sum(clf_predictions_X))\n",
    "    \n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    clf = LogisticRegression(random_state=0, penalty='l2', max_iter=max_iter).fit(training_data, labels) \n",
    "    clf_predictions = clf.predict(scores_transformed)\n",
    "    clf_predict_proba = clf.predict_proba(scores_transformed)[:,1]\n",
    "#     LR_threshold = np.array(np.sort(clf_predict_proba)[::-1])[int(sum(clf_predictions_X))]\n",
    "    print(\"F-1 score from LR:\",metrics.f1_score(y, np.array([int(i) for i in clf_predict_proba > LR_threshold])))\n",
    "    print('Number of outliers by LR: ', sum(np.array([int(i) for i in clf_predict_proba > LR_threshold])))\n",
    "    \n",
    "    agreed_outlier_indexes = np.where(np.sum(L,axis=1)==np.shape(L)[1])[0]\n",
    "    agreed_inlier_indexes = np.where(np.sum(L,axis=1)==0)[0]\n",
    "        \n",
    "    prediction_result_list.append(clf_predict_proba)\n",
    "    classifier_result_list.append(clf_predict_proba_X)\n",
    "    \n",
    "    prediction_list.append(np.array([int(i) for i in clf_predictions]))\n",
    "    \n",
    "    prediction_high_conf_outliers = np.intersect1d(np.where(prediction_result_list[-1] > high_confidence_threshold)[0],\n",
    "                                                   np.where(classifier_result_list[-1] > high_confidence_threshold)[0])\n",
    "#     print('length of prediction_high_conf_outliers:' , len(prediction_high_conf_outliers))\n",
    "    prediction_high_conf_inliers = np.intersect1d(np.where(prediction_result_list[-1] < low_confidence_threshold)[0],\n",
    "                                                   np.where(classifier_result_list[-1] < low_confidence_threshold)[0])\n",
    "#     print('length of prediction high conf inliers: ', len(prediction_high_conf_inliers))\n",
    "    \n",
    "    temp_prediction = np.array([int(i) for i in prediction_result_list[-1] > LR_threshold])\n",
    "    temp_classifier = np.array([int(i) for i in classifier_result_list[-1] > 0.5])\n",
    "    prediction_classifier_disagree = np.where(temp_prediction != temp_classifier)[0]\n",
    "#     print('length of prediction-classifier disagree: {}'.format(len(prediction_classifier_disagree)))\n",
    "#     print('length of prediction-classifier disagree in training: {}'.format(len(np.where(temp_prediction[data_indexes] != temp_classifier[data_indexes])[0])))\n",
    "    print(np.corrcoef(clf_predict_proba,clf_predict_proba_X))\n",
    "    two_prediction_corr.append(np.corrcoef(clf_predict_proba,clf_predict_proba_X)[0,1])\n",
    "\n",
    "    if np.max(coef_index_range) >= 2:\n",
    "#         if(len(prediction_high_conf_outliers) > 0 and len(prediction_high_conf_inliers) > 0):\n",
    "#             new_data_indexes = np.concatenate((prediction_high_conf_outliers, prediction_high_conf_inliers), axis = 0)\n",
    "#             new_data_indexes = np.array([int(i) for i in new_data_indexes])\n",
    "#             new_labels = np.concatenate((np.ones(len(prediction_high_conf_outliers)), np.zeros(len(prediction_high_conf_inliers))), axis = 0)\n",
    "#             clf_prune_2 = LogisticRegression(random_state=0, penalty='l2', max_iter=max_iter).fit(scores_transformed[new_data_indexes], new_labels) \n",
    "# #             print(\"F-1 score from both LR and SVM:\",metrics.f1_score(y, np.array([int(i) for i in clf_prune_2.predict_proba(scores_transformed)[:,1] > 0.5])))\n",
    "# #             print('Coef from both LR and SVM: ', clf_prune_2.coef_[0])\n",
    "#             combined_coef = clf_prune_2.coef_[0]  \n",
    "#         else:\n",
    "#             print('Coef from normal training: ', clf.coef_[0])\n",
    "        combined_coef = clf.coef_[0]\n",
    "#             print('Combined Coef: ',  combined_coef)\n",
    "\n",
    "        if(np.max(coef_index_range) >= 2 or \n",
    "           ((np.max(combined_coef)/np.min(combined_coef) >= 1.1) and np.max(coef_index_range) >= 2)):\n",
    "            if(len(set(combined_coef)) > 1):\n",
    "                cur_clf_coef = combined_coef \n",
    "                cutoff = max(max(0, np.mean(combined_coef)-np.std(combined_coef)),min(combined_coef))\n",
    "#                 print(cutoff)\n",
    "\n",
    "                remain_indexes_after_cond = (cur_clf_coef > cutoff) #np.logical_and(cur_clf_coef > cutoff, abs(cur_clf_coef) > 0.01) # # \n",
    "                remain_params_tracking = remain_params_tracking[remain_indexes_after_cond]\n",
    "                print(remain_params_tracking)\n",
    "                remain_indexes_after_cond_expanded = []\n",
    "                for i in range(0, len(coef_index_range)): #\n",
    "                    s_e_range = coef_index_range[i,1]-coef_index_range[i,0]\n",
    "                    s1, e1 = coef_index_range[i,0], coef_index_range[i,1]\n",
    "                    s2, e2 = index_range[i,0], index_range[i,1]\n",
    "                    saved_indexes = np.where(cur_clf_coef[s1:e1] > cutoff)[0]\n",
    "                    for j in range(N_size):\n",
    "                        remain_indexes_after_cond_expanded.extend(np.array(saved_indexes) + j * s_e_range + s2)\n",
    "\n",
    "                new_coef_index_range_seq = []\n",
    "                for i in range(0, len(coef_index_range)): #\n",
    "                    s, e = coef_index_range[i,0], coef_index_range[i,1]\n",
    "                    new_coef_index_range_seq.append(sum((remain_indexes_after_cond)[s:e]))\n",
    "\n",
    "                coef_index_range = []\n",
    "                index_range = []\n",
    "                cur_sum = 0\n",
    "                for i in range(0, len(new_coef_index_range_seq)):\n",
    "                    coef_index_range.append([cur_sum, cur_sum + new_coef_index_range_seq[i]])\n",
    "                    index_range.append([cur_sum * 6, 6 * (cur_sum + new_coef_index_range_seq[i])])\n",
    "                    cur_sum += new_coef_index_range_seq[i]\n",
    "\n",
    "                coef_index_range = np.array(coef_index_range)\n",
    "                index_range = np.array(index_range)\n",
    "                print(coef_index_range)\n",
    "#                 print(index_range)\n",
    "\n",
    "                L=L[:,remain_indexes_after_cond_expanded]\n",
    "                scores_for_training = scores_for_training[:, remain_indexes_after_cond]\n",
    "    if((len(last_training_data_indexes) == len(data_indexes)) and \n",
    "       (sum(last_training_data_indexes == data_indexes) == len(data_indexes)) and \n",
    "       (np.max(coef_index_range) < 2)):\n",
    "        counter =  counter + 1\n",
    "    else:\n",
    "        counter = 0\n",
    "    if(counter > 3):\n",
    "        break\n",
    "    last_training_data_indexes = data_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 120, 121, 122, 123, 124, 150]\n",
      "(5473, 26)\n",
      "Training data shape:  (4772, 26)\n",
      "Training data F-1 0.6003210272873194\n",
      "(4772, 10)\n",
      "(4772,)\n",
      "F-1 score from SVM: 0.5941780821917808\n",
      "F-1 score from LR: 0.5048923679060664\n",
      "Number of outliers by LR:  462\n",
      "length of prediction_high_conf_outliers: 294\n",
      "length of prediction high conf inliers:  4617\n",
      "[[1.         0.78396188]\n",
      " [0.78396188 1.        ]]\n",
      "F-1 score from both LR and SVM: 0.513888888888889\n",
      "Coef from both LR and SVM:  [ 0.000736    0.1481505   0.30282109  0.45315032  0.51761562  0.58038926\n",
      "  0.5933159   0.54739406  0.42410122  0.35553086 -0.05031496  0.01380261\n",
      "  0.0438868   0.03950137  0.03704462  0.03240052  0.02769839  0.01778991\n",
      "  0.01181254  0.01192402  0.15966538  0.16865174  0.16551874  0.16644401\n",
      "  0.15644075  0.32235327]\n",
      "0\n",
      "[ 0  1  2  3  4  5  6  7  8  9 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25]\n",
      "[[ 0 10]\n",
      " [10 19]\n",
      " [19 24]\n",
      " [24 25]]\n",
      "[[  0  60]\n",
      " [ 60 114]\n",
      " [114 144]\n",
      " [144 150]]\n"
     ]
    }
   ],
   "source": [
    "index_range = np.array([[0, 60], [60, 120], [120, 150], [150, 156]])\n",
    "coef_index_range = np.array([[0, 10], [10, 20], [20, 25], [25, 26]])\n",
    "coef_remain_index = range(156)\n",
    "\n",
    "scores_for_training_indexes = []\n",
    "for i in range(len(index_range)):\n",
    "    start=index_range[i][0]\n",
    "    temp_range = coef_index_range[i][1]-coef_index_range[i][0]\n",
    "    scores_for_training_indexes  = scores_for_training_indexes + list(range(start, start+temp_range))\n",
    "print(scores_for_training_indexes) \n",
    "scores_for_training = scores[:, np.array(scores_for_training_indexes)]\n",
    "print(np.shape(scores_for_training))\n",
    "\n",
    "transformer = RobustScaler().fit(scores_for_training)\n",
    "scores_transformed = transformer.transform(scores_for_training)\n",
    "training_data = scores_transformed[data_indexes]\n",
    "print('Training data shape: ', np.shape(training_data))\n",
    "training_data_F1.append(metrics.f1_score(y[data_indexes], labels))\n",
    "print('Training data F-1', metrics.f1_score(y[data_indexes], labels))\n",
    "\n",
    "transformer = RobustScaler().fit(X)\n",
    "X_transformed = transformer.transform(X)\n",
    "X_training_data = X_transformed[data_indexes]\n",
    "print(np.shape(X_training_data))\n",
    "print(np.shape(labels))\n",
    "\n",
    "clf_X = SVC(gamma='auto', probability=True, random_state=0)\n",
    "clf_X.fit(X_training_data, labels)\n",
    "clf_predictions_X = clf_X.predict(X_transformed)\n",
    "clf_predict_proba_X = clf_X.predict_proba(X_transformed)[:,1]\n",
    "print(\"F-1 score from SVM:\",metrics.f1_score(y, np.array([int(i) for i in clf_predict_proba_X > 0.5])))\n",
    "cur_f1_scores.append(metrics.f1_score(y, np.array([int(i) for i in clf_predict_proba_X > 0.5])))\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "clf = LogisticRegression(random_state=0, penalty='l2', max_iter=max_iter).fit(training_data, labels) \n",
    "clf_predictions = clf.predict(scores_transformed)\n",
    "clf_predict_proba = clf.predict_proba(scores_transformed)[:,1]\n",
    "# LR_threshold = np.array(np.sort(clf_predict_proba)[::-1])[int(sum(clf_predictions_X))]\n",
    "print(\"F-1 score from LR:\",metrics.f1_score(y, np.array([int(i) for i in clf_predict_proba > LR_threshold])))\n",
    "print('Number of outliers by LR: ', sum(np.array([int(i) for i in clf_predict_proba > LR_threshold])))\n",
    "\n",
    "\n",
    "agreed_outlier_indexes = np.where(np.sum(L,axis=1)==np.shape(L)[1])[0]\n",
    "agreed_inlier_indexes = np.where(np.sum(L,axis=1)==0)[0]\n",
    "\n",
    "prediction_result_list.append(clf_predict_proba)\n",
    "classifier_result_list.append(clf_predict_proba_X)\n",
    "\n",
    "prediction_list.append(np.array([int(i) for i in clf_predictions]))\n",
    "\n",
    "prediction_high_conf_outliers = np.intersect1d(np.where(prediction_result_list[-1] > high_confidence_threshold)[0],\n",
    "                                               np.where(classifier_result_list[-1] > high_confidence_threshold)[0])\n",
    "print('length of prediction_high_conf_outliers:' , len(prediction_high_conf_outliers))\n",
    "prediction_high_conf_inliers = np.intersect1d(np.where(prediction_result_list[-1] < low_confidence_threshold)[0],\n",
    "                                               np.where(classifier_result_list[-1] < low_confidence_threshold)[0])\n",
    "print('length of prediction high conf inliers: ', len(prediction_high_conf_inliers))\n",
    "\n",
    "temp_prediction = np.array([int(i) for i in prediction_result_list[-1] > LR_threshold])\n",
    "temp_classifier = np.array([int(i) for i in classifier_result_list[-1] > 0.5])\n",
    "prediction_classifier_disagree = np.where(temp_prediction != temp_classifier)[0]\n",
    "print(np.corrcoef(clf_predict_proba,clf_predict_proba_X))\n",
    "\n",
    "L = L_prev\n",
    "remain_params_tracking = np.array(range(0,np.max(coef_index_range)))\n",
    "\n",
    "if np.max(coef_index_range) >= 2:\n",
    "    if(len(prediction_high_conf_outliers) > 0 and len(prediction_high_conf_inliers) > 0):\n",
    "        new_data_indexes = np.concatenate((prediction_high_conf_outliers, prediction_high_conf_inliers), axis = 0)\n",
    "        new_data_indexes = np.array([int(i) for i in new_data_indexes])\n",
    "        new_labels = np.concatenate((np.ones(len(prediction_high_conf_outliers)), np.zeros(len(prediction_high_conf_inliers))), axis = 0)\n",
    "        clf_prune_2 = LogisticRegression(random_state=0, penalty='l2', max_iter=max_iter).fit(scores_transformed[new_data_indexes], new_labels) \n",
    "        print(\"F-1 score from both LR and SVM:\",metrics.f1_score(y, np.array([int(i) for i in clf_prune_2.predict_proba(scores_transformed)[:,1] > 0.5])))\n",
    "        print('Coef from both LR and SVM: ', clf_prune_2.coef_[0])\n",
    "        combined_coef = clf_prune_2.coef_[0]  \n",
    "    else:\n",
    "        print('Coef from normal training: ', clf.coef_[0])\n",
    "        combined_coef = clf.coef_[0]\n",
    "        print('Combined Coef: ',  combined_coef)\n",
    "\n",
    "    if(np.max(coef_index_range) > 2 or \n",
    "       ((np.max(combined_coef)/np.min(combined_coef) >= 1.1) and np.max(coef_index_range) >= 2)):\n",
    "        if(len(set(combined_coef)) > 1):\n",
    "            cur_clf_coef = combined_coef \n",
    "            cutoff = max(max(0, np.mean(combined_coef)-np.std(combined_coef)),min(combined_coef))\n",
    "            print(cutoff)\n",
    "\n",
    "            remain_indexes_after_cond = (cur_clf_coef > cutoff) #np.logical_and(cur_clf_coef > cutoff, abs(cur_clf_coef) > 0.01) # # \n",
    "            remain_params_tracking = remain_params_tracking[remain_indexes_after_cond]\n",
    "            print(remain_params_tracking)\n",
    "            remain_indexes_after_cond_expanded = []\n",
    "            for i in range(0, len(coef_index_range)): #\n",
    "                s_e_range = coef_index_range[i,1]-coef_index_range[i,0]\n",
    "                s1, e1 = coef_index_range[i,0], coef_index_range[i,1]\n",
    "                s2, e2 = index_range[i,0], index_range[i,1]\n",
    "                saved_indexes = np.where(cur_clf_coef[s1:e1] > cutoff)[0]\n",
    "                for j in range(N_size):\n",
    "                    remain_indexes_after_cond_expanded.extend(np.array(saved_indexes) + j * s_e_range + s2)\n",
    "\n",
    "            new_coef_index_range_seq = []\n",
    "            for i in range(0, len(coef_index_range)): #\n",
    "                s, e = coef_index_range[i,0], coef_index_range[i,1]\n",
    "                new_coef_index_range_seq.append(sum((remain_indexes_after_cond)[s:e]))\n",
    "\n",
    "            coef_index_range = []\n",
    "            index_range = []\n",
    "            cur_sum = 0\n",
    "            for i in range(0, len(new_coef_index_range_seq)):\n",
    "                coef_index_range.append([cur_sum, cur_sum + new_coef_index_range_seq[i]])\n",
    "                index_range.append([cur_sum * 6, 6 * (cur_sum + new_coef_index_range_seq[i])])\n",
    "                cur_sum += new_coef_index_range_seq[i]\n",
    "\n",
    "            coef_index_range = np.array(coef_index_range)\n",
    "            index_range = np.array(index_range)\n",
    "            print(coef_index_range)\n",
    "            print(index_range)\n",
    "\n",
    "            L=L[:,remain_indexes_after_cond_expanded]\n",
    "            scores_for_training = scores_for_training[:, remain_indexes_after_cond]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##################################################################\n",
      "Iteration = 0, L shape = (5473, 150)\n",
      "(4106, 10)\n",
      "(4106,)\n",
      "F-1 score from SVM: 0.5628373168851195\n",
      "F-1 score from LR: 0.5094482237339379\n",
      "Number of outliers by LR:  763\n",
      "[[1.         0.72055798]\n",
      " [0.72055798 1.        ]]\n",
      "[ 1  2  3  4  5  6  7  8  9 12 13 14 15 16 17 18 20 21 22 23 24 25]\n",
      "[[ 0  9]\n",
      " [ 9 16]\n",
      " [16 21]\n",
      " [21 22]]\n",
      "##################################################################\n",
      "Iteration = 1, L shape = (5473, 132)\n",
      "(4302, 10)\n",
      "(4302,)\n",
      "F-1 score from SVM: 0.558641975308642\n",
      "F-1 score from LR: 0.5079847908745247\n",
      "Number of outliers by LR:  755\n",
      "[[1.        0.7318044]\n",
      " [0.7318044 1.       ]]\n",
      "[ 1  2  3  4  5  6  7  8  9 12 13 20 21 22 23 24 25]\n",
      "[[ 0  9]\n",
      " [ 9 11]\n",
      " [11 16]\n",
      " [16 17]]\n",
      "##################################################################\n",
      "Iteration = 2, L shape = (5473, 102)\n",
      "(4331, 10)\n",
      "(4331,)\n",
      "F-1 score from SVM: 0.5607333842627961\n",
      "F-1 score from LR: 0.5132475397426193\n",
      "Number of outliers by LR:  761\n",
      "[[1.         0.73548605]\n",
      " [0.73548605 1.        ]]\n",
      "[ 2  3  4  5  6  7  8  9 12 13 20 21 22 23 24 25]\n",
      "[[ 0  8]\n",
      " [ 8 10]\n",
      " [10 15]\n",
      " [15 16]]\n",
      "##################################################################\n",
      "Iteration = 3, L shape = (5473, 96)\n",
      "(4407, 10)\n",
      "(4407,)\n",
      "F-1 score from SVM: 0.5611620795107034\n",
      "F-1 score from LR: 0.5182370820668692\n",
      "Number of outliers by LR:  756\n",
      "[[1.         0.73506765]\n",
      " [0.73506765 1.        ]]\n",
      "[ 2  3  4  5  6  7  8  9 20 21 22 23 24 25]\n",
      "[[ 0  8]\n",
      " [ 8  8]\n",
      " [ 8 13]\n",
      " [13 14]]\n",
      "##################################################################\n",
      "Iteration = 4, L shape = (5473, 84)\n",
      "(4461, 10)\n",
      "(4461,)\n",
      "F-1 score from SVM: 0.5622612681436211\n",
      "F-1 score from LR: 0.522399392558846\n",
      "Number of outliers by LR:  757\n",
      "[[1.         0.73365408]\n",
      " [0.73365408 1.        ]]\n",
      "[ 2  3  4  5  6  7  8  9 23 25]\n",
      "[[ 0  8]\n",
      " [ 8  8]\n",
      " [ 8  9]\n",
      " [ 9 10]]\n",
      "##################################################################\n",
      "Iteration = 5, L shape = (5473, 60)\n",
      "(4470, 10)\n",
      "(4470,)\n",
      "F-1 score from SVM: 0.5618320610687023\n",
      "F-1 score from LR: 0.5258358662613982\n",
      "Number of outliers by LR:  756\n",
      "[[1.         0.72005811]\n",
      " [0.72005811 1.        ]]\n",
      "[ 2  3  4  5  6  7  8  9 25]\n",
      "[[0 8]\n",
      " [8 8]\n",
      " [8 8]\n",
      " [8 9]]\n",
      "##################################################################\n",
      "Iteration = 6, L shape = (5473, 54)\n",
      "(4472, 10)\n",
      "(4472,)\n",
      "F-1 score from SVM: 0.5600612088752869\n",
      "F-1 score from LR: 0.5258358662613982\n",
      "Number of outliers by LR:  756\n",
      "[[1.         0.71070513]\n",
      " [0.71070513 1.        ]]\n",
      "[ 2  3  5  6  7  8  9 25]\n",
      "[[0 7]\n",
      " [7 7]\n",
      " [7 7]\n",
      " [7 8]]\n",
      "##################################################################\n",
      "Iteration = 7, L shape = (5473, 48)\n",
      "(4471, 10)\n",
      "(4471,)\n",
      "F-1 score from SVM: 0.5622612681436211\n",
      "F-1 score from LR: 0.5303951367781156\n",
      "Number of outliers by LR:  756\n",
      "[[1.         0.71151399]\n",
      " [0.71151399 1.        ]]\n",
      "[ 2  3  5  6  7  8 25]\n",
      "[[0 6]\n",
      " [6 6]\n",
      " [6 6]\n",
      " [6 7]]\n",
      "##################################################################\n",
      "Iteration = 8, L shape = (5473, 42)\n",
      "(4481, 10)\n",
      "(4481,)\n",
      "F-1 score from SVM: 0.5609756097560975\n",
      "F-1 score from LR: 0.532319391634981\n",
      "Number of outliers by LR:  755\n",
      "[[1.         0.71097437]\n",
      " [0.71097437 1.        ]]\n",
      "[ 3  5  6  7  8 25]\n",
      "[[0 5]\n",
      " [5 5]\n",
      " [5 5]\n",
      " [5 6]]\n",
      "##################################################################\n",
      "Iteration = 9, L shape = (5473, 36)\n",
      "(4529, 10)\n",
      "(4529,)\n",
      "F-1 score from SVM: 0.5624521072796935\n",
      "F-1 score from LR: 0.5350609756097561\n",
      "Number of outliers by LR:  752\n",
      "[[1.         0.72944519]\n",
      " [0.72944519 1.        ]]\n",
      "[ 3  5  6  7 25]\n",
      "[[0 4]\n",
      " [4 4]\n",
      " [4 4]\n",
      " [4 5]]\n",
      "##################################################################\n",
      "Iteration = 10, L shape = (5473, 30)\n",
      "(4544, 10)\n",
      "(4544,)\n",
      "F-1 score from SVM: 0.565284178187404\n",
      "F-1 score from LR: 0.5306748466257669\n",
      "Number of outliers by LR:  744\n",
      "[[1.         0.73568585]\n",
      " [0.73568585 1.        ]]\n",
      "[ 3  5  7 25]\n",
      "[[0 3]\n",
      " [3 3]\n",
      " [3 3]\n",
      " [3 4]]\n",
      "##################################################################\n",
      "Iteration = 11, L shape = (5473, 24)\n",
      "(4550, 10)\n",
      "(4550,)\n",
      "F-1 score from SVM: 0.5679012345679013\n",
      "F-1 score from LR: 0.5354938271604938\n",
      "Number of outliers by LR:  736\n",
      "[[1.         0.74685087]\n",
      " [0.74685087 1.        ]]\n",
      "[ 5  7 25]\n",
      "[[0 2]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [2 3]]\n",
      "##################################################################\n",
      "Iteration = 12, L shape = (5473, 18)\n",
      "(4592, 10)\n",
      "(4592,)\n",
      "F-1 score from SVM: 0.5729898516783762\n",
      "F-1 score from LR: 0.5372670807453416\n",
      "Number of outliers by LR:  728\n",
      "[[1.         0.78733999]\n",
      " [0.78733999 1.        ]]\n",
      "[ 5 25]\n",
      "[[0 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 2]]\n",
      "##################################################################\n",
      "Iteration = 13, L shape = (5473, 12)\n",
      "(4635, 10)\n",
      "(4635,)\n",
      "F-1 score from SVM: 0.5734375\n",
      "F-1 score from LR: 0.5300077942322681\n",
      "Number of outliers by LR:  723\n",
      "[[1.         0.79439986]\n",
      " [0.79439986 1.        ]]\n",
      "[5]\n",
      "[[0 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]]\n",
      "##################################################################\n",
      "Iteration = 14, L shape = (5473, 6)\n",
      "(4670, 10)\n",
      "(4670,)\n",
      "F-1 score from SVM: 0.6015625\n",
      "F-1 score from LR: 0.48727833461835\n",
      "Number of outliers by LR:  737\n",
      "[[1.        0.6778447]\n",
      " [0.6778447 1.       ]]\n",
      "##################################################################\n",
      "Iteration = 15, L shape = (5473, 6)\n",
      "(4495, 10)\n",
      "(4495,)\n",
      "F-1 score from SVM: 0.6112852664576802\n",
      "F-1 score from LR: 0.48944487881157156\n",
      "Number of outliers by LR:  719\n",
      "[[1.         0.70087071]\n",
      " [0.70087071 1.        ]]\n",
      "##################################################################\n",
      "Iteration = 16, L shape = (5473, 6)\n",
      "(4532, 10)\n",
      "(4532,)\n",
      "F-1 score from SVM: 0.6188976377952756\n",
      "F-1 score from LR: 0.49014972419227737\n",
      "Number of outliers by LR:  709\n",
      "[[1.         0.71016558]\n",
      " [0.71016558 1.        ]]\n",
      "##################################################################\n",
      "Iteration = 17, L shape = (5473, 6)\n",
      "(4594, 10)\n",
      "(4594,)\n",
      "F-1 score from SVM: 0.6213438735177865\n",
      "F-1 score from LR: 0.491699604743083\n",
      "Number of outliers by LR:  705\n",
      "[[1.         0.71740723]\n",
      " [0.71740723 1.        ]]\n",
      "##################################################################\n",
      "Iteration = 18, L shape = (5473, 6)\n",
      "(4653, 10)\n",
      "(4653,)\n",
      "F-1 score from SVM: 0.6285714285714287\n",
      "F-1 score from LR: 0.4972022382094325\n",
      "Number of outliers by LR:  691\n",
      "[[1.         0.70750332]\n",
      " [0.70750332 1.        ]]\n",
      "##################################################################\n",
      "Iteration = 19, L shape = (5473, 6)\n",
      "(4655, 10)\n",
      "(4655,)\n",
      "F-1 score from SVM: 0.632\n",
      "F-1 score from LR: 0.497584541062802\n",
      "Number of outliers by LR:  682\n",
      "[[1.         0.70958983]\n",
      " [0.70958983 1.        ]]\n",
      "##################################################################\n",
      "Iteration = 20, L shape = (5473, 6)\n",
      "(4672, 10)\n",
      "(4672,)\n",
      "F-1 score from SVM: 0.6425196850393701\n",
      "F-1 score from LR: 0.4979854955680903\n",
      "Number of outliers by LR:  681\n",
      "[[1.         0.70352795]\n",
      " [0.70352795 1.        ]]\n",
      "##################################################################\n",
      "Iteration = 21, L shape = (5473, 6)\n",
      "(4678, 10)\n",
      "(4678,)\n",
      "F-1 score from SVM: 0.6489444878811572\n",
      "F-1 score from LR: 0.49919743178170145\n",
      "Number of outliers by LR:  686\n",
      "[[1.         0.70148536]\n",
      " [0.70148536 1.        ]]\n",
      "##################################################################\n",
      "Iteration = 22, L shape = (5473, 6)\n",
      "(4678, 10)\n",
      "(4678,)\n",
      "F-1 score from SVM: 0.6552529182879376\n",
      "F-1 score from LR: 0.494435612082671\n",
      "Number of outliers by LR:  698\n",
      "[[1.         0.70296854]\n",
      " [0.70296854 1.        ]]\n",
      "##################################################################\n",
      "Iteration = 23, L shape = (5473, 6)\n",
      "(4681, 10)\n",
      "(4681,)\n",
      "F-1 score from SVM: 0.6468285043069695\n",
      "F-1 score from LR: 0.49053627760252366\n",
      "Number of outliers by LR:  708\n",
      "[[1.         0.69787874]\n",
      " [0.69787874 1.        ]]\n",
      "##################################################################\n",
      "Iteration = 24, L shape = (5473, 6)\n",
      "(4679, 10)\n",
      "(4679,)\n",
      "F-1 score from SVM: 0.65\n",
      "F-1 score from LR: 0.49014972419227737\n",
      "Number of outliers by LR:  709\n",
      "[[1.         0.69768805]\n",
      " [0.69768805 1.        ]]\n",
      "##################################################################\n",
      "Iteration = 25, L shape = (5473, 6)\n",
      "(4682, 10)\n",
      "(4682,)\n",
      "F-1 score from SVM: 0.6514913657770801\n",
      "F-1 score from LR: 0.4924782264449723\n",
      "Number of outliers by LR:  703\n",
      "[[1.         0.70153118]\n",
      " [0.70153118 1.        ]]\n",
      "##################################################################\n",
      "Iteration = 26, L shape = (5473, 6)\n",
      "(4686, 10)\n",
      "(4686,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-1 score from SVM: 0.6525490196078432\n",
      "F-1 score from LR: 0.4924782264449723\n",
      "Number of outliers by LR:  703\n",
      "[[1.         0.69992274]\n",
      " [0.69992274 1.        ]]\n",
      "##################################################################\n",
      "Iteration = 27, L shape = (5473, 6)\n",
      "(4688, 10)\n",
      "(4688,)\n",
      "F-1 score from SVM: 0.6552262090483619\n",
      "F-1 score from LR: 0.4924782264449723\n",
      "Number of outliers by LR:  703\n",
      "[[1.         0.69654257]\n",
      " [0.69654257 1.        ]]\n",
      "##################################################################\n",
      "Iteration = 28, L shape = (5473, 6)\n",
      "(4689, 10)\n",
      "(4689,)\n",
      "F-1 score from SVM: 0.6599378881987578\n",
      "F-1 score from LR: 0.49014972419227737\n",
      "Number of outliers by LR:  709\n",
      "[[1.         0.69528068]\n",
      " [0.69528068 1.        ]]\n",
      "##################################################################\n",
      "Iteration = 29, L shape = (5473, 6)\n",
      "(4689, 10)\n",
      "(4689,)\n",
      "F-1 score from SVM: 0.6599378881987578\n",
      "F-1 score from LR: 0.49014972419227737\n",
      "Number of outliers by LR:  709\n",
      "[[1.         0.69528068]\n",
      " [0.69528068 1.        ]]\n",
      "##################################################################\n",
      "Iteration = 30, L shape = (5473, 6)\n",
      "(4689, 10)\n",
      "(4689,)\n",
      "F-1 score from SVM: 0.6599378881987578\n",
      "F-1 score from LR: 0.49014972419227737\n",
      "Number of outliers by LR:  709\n",
      "[[1.         0.69528068]\n",
      " [0.69528068 1.        ]]\n",
      "##################################################################\n",
      "Iteration = 31, L shape = (5473, 6)\n",
      "(4689, 10)\n",
      "(4689,)\n",
      "F-1 score from SVM: 0.6599378881987578\n",
      "F-1 score from LR: 0.49014972419227737\n",
      "Number of outliers by LR:  709\n",
      "[[1.         0.69528068]\n",
      " [0.69528068 1.        ]]\n",
      "##################################################################\n",
      "Iteration = 32, L shape = (5473, 6)\n",
      "(4689, 10)\n",
      "(4689,)\n",
      "F-1 score from SVM: 0.6599378881987578\n",
      "F-1 score from LR: 0.49014972419227737\n",
      "Number of outliers by LR:  709\n",
      "[[1.         0.69528068]\n",
      " [0.69528068 1.        ]]\n"
     ]
    }
   ],
   "source": [
    "last_training_data_indexes = []\n",
    "counter = 0\n",
    "\n",
    "for i_range in range(0, 50):\n",
    "    print(\"##################################################################\")\n",
    "    print('Iteration = {}, L shape = {}'.format(i_range, np.shape(L)))\n",
    "    num_methods = np.shape(L)[1]\n",
    "\n",
    "#     agree_outlier_indexes = (np.sum(L,axis=1)==np.shape(L)[1])\n",
    "#     print('All agree, Number of outliers = {}'.format(sum(agree_outlier_indexes)))\n",
    "#     agree_inlier_indexes = (np.sum(L,axis=1)==0)\n",
    "#     print('All agree, Number of inliers = {}'.format(sum(agree_inlier_indexes)))\n",
    "\n",
    "#     all_inlier_indexes = np.union1d(np.setdiff1d(np.where(agree_inlier_indexes)[0], prediction_high_conf_outliers), prediction_high_conf_inliers)\n",
    "#     print('num of inliers = {}'.format(np.shape(all_inlier_indexes)[0]))\n",
    "#     all_outlier_indexes = np.union1d(np.where(agree_outlier_indexes)[0], prediction_high_conf_outliers)\n",
    "#     print('num of outliers = {}'.format(np.shape(all_outlier_indexes)[0]))\n",
    "\n",
    "#     disagree_indexes = np.where(np.logical_or(np.sum(L,axis = 1)==0, np.sum(L,axis = 1)==num_methods)==0)[0]\n",
    "\n",
    "    ########################################################################\n",
    "\n",
    "    agree_outlier_indexes = np.sum(L,axis=1)==np.shape(L)[1]\n",
    "#     print('All agree, Number of outliers = {}'.format(sum(agree_outlier_indexes)))\n",
    "    agree_inlier_indexes = np.sum(L,axis=1)==0\n",
    "#     print('All agree, Number of inliers = {}'.format(sum(agree_inlier_indexes)))\n",
    "\n",
    "    disagree_indexes = np.where(np.logical_or(np.sum(L,axis = 1)==0, np.sum(L,axis = 1)==num_methods)==0)[0]\n",
    "    # print('Number of disagreed points = {}'.format(len(disagree_indexes)))\n",
    "    # print('Number of disagreed points (true outliers) = {}'.format(sum(y[disagree_indexes] == 1)))\n",
    "    # print('Number of disagreed points (true inliers) = {}'.format(sum(y[disagree_indexes] == 0)))\n",
    "\n",
    "#     all_inlier_indexes = np.where(agree_inlier_indexes)[0]\n",
    "    all_inlier_indexes = np.setdiff1d(np.where(agree_inlier_indexes)[0], prediction_high_conf_outliers)\n",
    "    if len(prediction_high_conf_inliers) >0:\n",
    "        all_inlier_indexes = np.intersect1d(np.setdiff1d(np.where(agree_inlier_indexes)[0], prediction_high_conf_outliers), prediction_high_conf_inliers)\n",
    "#     print('num of inliers = {}'.format(np.shape(all_inlier_indexes)[0]))\n",
    "#     all_outlier_indexes = np.union1d(np.where(agree_outlier_indexes)[0], self_agree_index_list)\n",
    "\n",
    "#     if(len(np.intersect1d(np.where(agree_outlier_indexes)[0], prediction_high_conf_outliers)) > 0 and\n",
    "#       (len(np.union1d(np.where(agree_outlier_indexes)[0], prediction_high_conf_outliers)) > 2000)):\n",
    "#         all_outlier_indexes = np.intersect1d(np.where(agree_outlier_indexes)[0], prediction_high_conf_outliers)\n",
    "#     else:\n",
    "    all_outlier_indexes = np.union1d(np.where(agree_outlier_indexes)[0], prediction_high_conf_outliers)\n",
    "#     if(len(all_outlier_indexes) > 1000):\n",
    "#         all_outlier_indexes = np.random.RandomState(1).permutation(all_outlier_indexes)[:1000]\n",
    "        \n",
    "#     all_outlier_indexes = np.union1d(np.where(agree_outlier_indexes)[0], prediction_high_conf_outliers)\n",
    "#     print('num of outliers = {}'.format(np.shape(all_outlier_indexes)[0]))\n",
    "    all_inlier_indexes = np.setdiff1d(all_inlier_indexes, prediction_classifier_disagree)\n",
    "    \n",
    "    self_agree_index_list = []\n",
    "    if((len(all_outlier_indexes) == 0) or (len(all_inlier_indexes)/ len(all_outlier_indexes) > 1000)):\n",
    "        for i in range(0, len(index_range)):\n",
    "            if(index_range[i,1]-index_range[i,0] <= 6):\n",
    "                continue\n",
    "            temp_index = disagree_indexes[np.where(np.sum(L[disagree_indexes][:,index_range[i,0]: index_range[i,1]], axis = 1)==(index_range[i,1]-index_range[i,0]))[0]]\n",
    "            self_agree_index_list = np.union1d(self_agree_index_list, temp_index)\n",
    "        self_agree_index_list = [int(i) for i in self_agree_index_list]\n",
    "#     self_agree_index_list = np.random.RandomState(1).permutation(self_agree_index_list)[:500]\n",
    "    all_outlier_indexes = np.union1d(all_outlier_indexes, self_agree_index_list)\n",
    "    all_outlier_indexes = np.setdiff1d(all_outlier_indexes, prediction_classifier_disagree)\n",
    "#     print('num of outliers = {}'.format(np.shape(all_outlier_indexes)[0]))\n",
    "    \n",
    "    \n",
    "    from sklearn.preprocessing import RobustScaler\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    data_indexes = np.concatenate((all_inlier_indexes, all_outlier_indexes), axis = 0)\n",
    "    data_indexes = np.array([int(i) for i in data_indexes])\n",
    "    labels = np.concatenate((np.zeros(len(all_inlier_indexes)), np.ones(len(all_outlier_indexes))), axis = 0)\n",
    "    transformer = RobustScaler().fit(scores_for_training)\n",
    "    scores_transformed = transformer.transform(scores_for_training)\n",
    "    training_data = scores_transformed[data_indexes]\n",
    "#     print('Training data shape: ', np.shape(training_data))\n",
    "    training_data_F1.append(metrics.f1_score(y[data_indexes], labels))\n",
    "#     print('Training data F-1', metrics.f1_score(y[data_indexes], labels))\n",
    "    \n",
    "    transformer = RobustScaler().fit(X)\n",
    "    X_transformed = transformer.transform(X)\n",
    "    X_training_data = X_transformed[data_indexes]\n",
    "    print(np.shape(X_training_data))\n",
    "    print(np.shape(labels))\n",
    "\n",
    "    clf_X = SVC(gamma='auto', probability=True, random_state=0)\n",
    "    clf_X.fit(X_training_data, labels)\n",
    "    clf_predictions_X = clf_X.predict(X_transformed)\n",
    "    clf_predict_proba_X = clf_X.predict_proba(X_transformed)[:,1]\n",
    "    print(\"F-1 score from SVM:\",metrics.f1_score(y, np.array([int(i) for i in clf_predict_proba_X > 0.5])))\n",
    "    cur_f1_scores.append(metrics.f1_score(y, np.array([int(i) for i in clf_predict_proba_X > 0.5])))\n",
    "    \n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    from sklearn.svm import SVC\n",
    "    clf = LogisticRegression(random_state=0, penalty='l2', max_iter=max_iter).fit(training_data, labels) \n",
    "    clf_predictions = clf.predict(scores_transformed)\n",
    "    clf_predict_proba = clf.predict_proba(scores_transformed)[:,1]\n",
    "    LR_threshold = np.array(np.sort(clf_predict_proba)[::-1])[int(sum(clf_predictions_X))]\n",
    "    print(\"F-1 score from LR:\",metrics.f1_score(y, np.array([int(i) for i in clf_predict_proba > LR_threshold])))\n",
    "    print('Number of outliers by LR: ', sum(np.array([int(i) for i in clf_predict_proba > LR_threshold])))\n",
    "    \n",
    "    \n",
    "    agreed_outlier_indexes = np.where(np.sum(L,axis=1)==np.shape(L)[1])[0]\n",
    "    agreed_inlier_indexes = np.where(np.sum(L,axis=1)==0)[0]\n",
    "        \n",
    "    prediction_result_list.append(clf_predict_proba)\n",
    "    classifier_result_list.append(clf_predict_proba_X)\n",
    "    \n",
    "    prediction_list.append(np.array([int(i) for i in clf_predictions]))\n",
    "    print(np.corrcoef(clf_predict_proba,clf_predict_proba_X))\n",
    "    \n",
    "    prediction_high_conf_outliers = np.intersect1d(np.where(prediction_result_list[-1] > high_confidence_threshold)[0],\n",
    "                                                   np.where(classifier_result_list[-1] > high_confidence_threshold)[0])\n",
    "#     print('length of prediction_high_conf_outliers:' , len(prediction_high_conf_outliers))\n",
    "    prediction_high_conf_inliers = np.intersect1d(np.where(prediction_result_list[-1] < low_confidence_threshold)[0],\n",
    "                                                   np.where(classifier_result_list[-1] < low_confidence_threshold)[0])\n",
    "#     print('length of prediction high conf inliers: ', len(prediction_high_conf_inliers))\n",
    "    \n",
    "    temp_prediction = np.array([int(i) for i in prediction_result_list[-1] > LR_threshold])\n",
    "    temp_classifier = np.array([int(i) for i in classifier_result_list[-1] > 0.5])\n",
    "    prediction_classifier_disagree = np.where(temp_prediction != temp_classifier)[0]\n",
    "    \n",
    "    if np.max(coef_index_range) >= 2:\n",
    "        if(len(prediction_high_conf_outliers) > 0 and len(prediction_high_conf_inliers) > 0):\n",
    "            new_data_indexes = np.concatenate((prediction_high_conf_outliers, prediction_high_conf_inliers), axis = 0)\n",
    "            new_data_indexes = np.array([int(i) for i in new_data_indexes])\n",
    "            new_labels = np.concatenate((np.ones(len(prediction_high_conf_outliers)), np.zeros(len(prediction_high_conf_inliers))), axis = 0)\n",
    "            clf_prune_2 = LogisticRegression(random_state=0, penalty='l2', max_iter=max_iter).fit(scores_transformed[new_data_indexes], new_labels) \n",
    "#             print(\"F-1 score from both LR and SVM:\",metrics.f1_score(y, np.array([int(i) for i in clf_prune_2.predict_proba(scores_transformed)[:,1] > 0.5])))\n",
    "#             print('Coef from both LR and SVM: ', clf_prune_2.coef_[0])\n",
    "            combined_coef = clf_prune_2.coef_[0]  \n",
    "        else:\n",
    "#             print('Coef from normal training: ', clf.coef_[0])\n",
    "            combined_coef = clf.coef_[0]\n",
    "#             print('Combined Coef: ',  combined_coef)\n",
    "\n",
    "        if(np.max(coef_index_range) >= 2 or \n",
    "           ((np.max(combined_coef)/np.min(combined_coef) >= 1.1) and np.max(coef_index_range) >= 2)):\n",
    "            if(len(set(combined_coef)) > 1):\n",
    "                cur_clf_coef = combined_coef \n",
    "                cutoff = max(max(0, np.mean(combined_coef)-np.std(combined_coef)),min(combined_coef))\n",
    "#                 print(cutoff)\n",
    "\n",
    "                remain_indexes_after_cond = (cur_clf_coef > cutoff) #np.logical_and(cur_clf_coef > cutoff, abs(cur_clf_coef) > 0.01) # # \n",
    "                remain_params_tracking = remain_params_tracking[remain_indexes_after_cond]\n",
    "                print(remain_params_tracking)\n",
    "                remain_indexes_after_cond_expanded = []\n",
    "                for i in range(0, len(coef_index_range)): #\n",
    "                    s_e_range = coef_index_range[i,1]-coef_index_range[i,0]\n",
    "                    s1, e1 = coef_index_range[i,0], coef_index_range[i,1]\n",
    "                    s2, e2 = index_range[i,0], index_range[i,1]\n",
    "                    saved_indexes = np.where(cur_clf_coef[s1:e1] > cutoff)[0]\n",
    "                    for j in range(N_size):\n",
    "                        remain_indexes_after_cond_expanded.extend(np.array(saved_indexes) + j * s_e_range + s2)\n",
    "\n",
    "                new_coef_index_range_seq = []\n",
    "                for i in range(0, len(coef_index_range)): #\n",
    "                    s, e = coef_index_range[i,0], coef_index_range[i,1]\n",
    "                    new_coef_index_range_seq.append(sum((remain_indexes_after_cond)[s:e]))\n",
    "\n",
    "                coef_index_range = []\n",
    "                index_range = []\n",
    "                cur_sum = 0\n",
    "                for i in range(0, len(new_coef_index_range_seq)):\n",
    "                    coef_index_range.append([cur_sum, cur_sum + new_coef_index_range_seq[i]])\n",
    "                    index_range.append([cur_sum * 6, 6 * (cur_sum + new_coef_index_range_seq[i])])\n",
    "                    cur_sum += new_coef_index_range_seq[i]\n",
    "\n",
    "                coef_index_range = np.array(coef_index_range)\n",
    "                index_range = np.array(index_range)\n",
    "                print(coef_index_range)\n",
    "#                 print(index_range)\n",
    "\n",
    "                L=L[:,remain_indexes_after_cond_expanded]\n",
    "                scores_for_training = scores_for_training[:, remain_indexes_after_cond]\n",
    "    if((len(last_training_data_indexes) == len(data_indexes)) and \n",
    "       (sum(last_training_data_indexes == data_indexes) == len(data_indexes)) and \n",
    "       (np.max(coef_index_range) < 2)):\n",
    "        counter =  counter + 1\n",
    "    else:\n",
    "        counter = 0\n",
    "    if(counter > 3):\n",
    "        break\n",
    "    last_training_data_indexes = data_indexes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
